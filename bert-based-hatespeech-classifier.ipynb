{"cells":[{"cell_type":"markdown","metadata":{"id":"GWvJjo_0foas"},"source":["# Installing and Importing necessary modules"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-12-11T11:13:49.689042Z","iopub.status.busy":"2023-12-11T11:13:49.688604Z","iopub.status.idle":"2023-12-11T11:14:01.464602Z","shell.execute_reply":"2023-12-11T11:14:01.463243Z","shell.execute_reply.started":"2023-12-11T11:13:49.689009Z"},"id":"y9w3EXQCGym1","outputId":"5a460018-ced0-4f25-9a46-a31dd4117ed9","trusted":true},"outputs":[],"source":["!pip install transformers gdown -q"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-12-11T12:26:37.912329Z","iopub.status.busy":"2023-12-11T12:26:37.911578Z","iopub.status.idle":"2023-12-11T12:26:38.027520Z","shell.execute_reply":"2023-12-11T12:26:38.026513Z","shell.execute_reply.started":"2023-12-11T12:26:37.912292Z"},"id":"E8MV4XQ5WUAN","outputId":"ab817717-46e0-4032-92e2-b3387a8c1d83","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}],"source":["import numpy as np\n","from nltk.tokenize import word_tokenize\n","import pandas as pd\n","import nltk\n","from nltk.corpus import stopwords\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import gdown\n","import re\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import BertTokenizer, BertModel\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.utils.class_weight import compute_class_weight\n","import torch.nn.functional as F\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_colwidth', None)\n","pd.set_option('display.max_rows', None)"]},{"cell_type":"markdown","metadata":{"id":"giJxdZMe1oij"},"source":["# Reading Data\n"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"execution":{"iopub.execute_input":"2023-12-11T12:26:38.332622Z","iopub.status.busy":"2023-12-11T12:26:38.331543Z","iopub.status.idle":"2023-12-11T12:26:42.289533Z","shell.execute_reply":"2023-12-11T12:26:42.288582Z","shell.execute_reply.started":"2023-12-11T12:26:38.332556Z"},"id":"zNtDx5YA2L7L","outputId":"e25d557d-6b81-4ae6-cef7-020b80ac41ea","trusted":true},"outputs":[{"data":{"text/plain":["'valid.tsv'"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["output = 'test.tsv'\n","gdown.download(f'https://drive.google.com/file/d/19hRm27ej0uHfYP_N5lMkPQEfEVTHy1HL/view?usp=sharing', output, quiet=True,fuzzy=True)\n","\n","output = 'train.tsv'\n","gdown.download(f'https://drive.google.com/file/d/1x6KGEdVo2UwcLgOoUYbUXTcC1zEM4iDW/view?usp=sharing', output, quiet=True,fuzzy=True)\n","\n","output = 'valid.tsv'\n","gdown.download(f'https://drive.google.com/file/d/1VncNy3EZrak1-lh0G5ne2hBCSpPmIJqN/view?usp=sharing', output, quiet=True,fuzzy=True)"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":150},"execution":{"iopub.execute_input":"2023-12-11T12:26:42.291276Z","iopub.status.busy":"2023-12-11T12:26:42.290994Z","iopub.status.idle":"2023-12-11T12:26:42.353373Z","shell.execute_reply":"2023-12-11T12:26:42.352460Z","shell.execute_reply.started":"2023-12-11T12:26:42.291252Z"},"id":"glSr3M-D2Qly","outputId":"bb282646-14f2-4f44-c331-c66eb0a3c841","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Comment</th>\n","      <th>Comment Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>we cannot continue calling ourselves feminists if the rights of all womxn arent addressed yes to a sexual offences public list but will a trans lesbian bisexual and queer womxn be able to enter their information on the reporting sheet gender forum</td>\n","      <td>normal</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                                                                                                                                                                                                                   Comment  \\\n","0  we cannot continue calling ourselves feminists if the rights of all womxn arent addressed yes to a sexual offences public list but will a trans lesbian bisexual and queer womxn be able to enter their information on the reporting sheet gender forum   \n","\n","  Comment Label  \n","0        normal  "]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["test_cols = ['Comment', 'Comment Label']\n","df_test = pd.read_csv('test.tsv',sep='\\t',names=test_cols)\n","df_train = pd.read_csv('train.tsv',sep='\\t',names=test_cols)\n","df_valid = pd.read_csv('valid.tsv', sep='\\t',names =test_cols)\n","df_train.head(1)"]},{"cell_type":"markdown","metadata":{"id":"pToKYM4N-JdU"},"source":["1. Preprocess the data, remove unnecessary symbols, stop words,\n","etc."]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:26:42.355119Z","iopub.status.busy":"2023-12-11T12:26:42.354846Z","iopub.status.idle":"2023-12-11T12:26:42.359475Z","shell.execute_reply":"2023-12-11T12:26:42.358529Z","shell.execute_reply.started":"2023-12-11T12:26:42.355096Z"},"id":"5s4i3CVVWUAO","trusted":true},"outputs":[],"source":["def preprocess_text(sentence,token=None):\n","    sentence = sentence.lower()\n","    sentence = re.sub(r'\\d+', '', sentence) #Remove numbers\n","    # There is no need to preprocess other things because bert can handle all the other things internally\n","    return sentence"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":150},"execution":{"iopub.execute_input":"2023-12-11T12:26:42.361611Z","iopub.status.busy":"2023-12-11T12:26:42.361343Z","iopub.status.idle":"2023-12-11T12:26:42.492831Z","shell.execute_reply":"2023-12-11T12:26:42.491988Z","shell.execute_reply.started":"2023-12-11T12:26:42.361587Z"},"id":"8f6_mn-jWUAP","outputId":"0800723f-b77c-4785-9eaa-e328bf85ca5f","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Comment</th>\n","      <th>Comment Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>we cannot continue calling ourselves feminists if the rights of all womxn arent addressed yes to a sexual offences public list but will a trans lesbian bisexual and queer womxn be able to enter their information on the reporting sheet gender forum</td>\n","      <td>normal</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                                                                                                                                                                                                                   Comment  \\\n","0  we cannot continue calling ourselves feminists if the rights of all womxn arent addressed yes to a sexual offences public list but will a trans lesbian bisexual and queer womxn be able to enter their information on the reporting sheet gender forum   \n","\n","  Comment Label  \n","0        normal  "]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["df_train['Comment'] = df_train['Comment'].apply(preprocess_text)\n","df_test['Comment'] = df_test['Comment'].apply(preprocess_text)\n","df_valid['Comment'] = df_valid['Comment'].apply(preprocess_text)\n","df_train.head(1)"]},{"cell_type":"markdown","metadata":{"id":"PZ6Tyasg-NwY"},"source":["2. Load the Model & Tokenizer from the huggingface library."]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"referenced_widgets":["4fa513f99c2b44cb9aacc37dadb963bb","fbf630853ffa43a69c8fd4d722438ab8","02dd9798a1f54a079f87d1e4ca5efc01","9e7e9bbe8ad94232b3004601c4cb6374"]},"execution":{"iopub.execute_input":"2023-12-11T12:26:42.494122Z","iopub.status.busy":"2023-12-11T12:26:42.493866Z","iopub.status.idle":"2023-12-11T12:26:43.933855Z","shell.execute_reply":"2023-12-11T12:26:43.933058Z","shell.execute_reply.started":"2023-12-11T12:26:42.494099Z"},"id":"WiWjwZMsWUAO","outputId":"4d5971c8-daeb-41e0-fee6-468b602d4188","trusted":true},"outputs":[],"source":["# For colab\n","\n","model_name = 'bert-base-uncased'\n","\n","bert = BertModel.from_pretrained(model_name)\n","tokenizer = BertTokenizer.from_pretrained(model_name)"]},{"cell_type":"markdown","metadata":{"id":"7w7VF6Qz-89o"},"source":["3. Design the dataloader class for tokenising and batch-processing\n","the input data."]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:26:43.935767Z","iopub.status.busy":"2023-12-11T12:26:43.935476Z","iopub.status.idle":"2023-12-11T12:26:43.943776Z","shell.execute_reply":"2023-12-11T12:26:43.942759Z","shell.execute_reply.started":"2023-12-11T12:26:43.935741Z"},"id":"fG0c7KuRWUAP","trusted":true},"outputs":[],"source":["class MyDataset(Dataset):\n","    def __init__(self, tokenizer, texts, labels,max_length,label_encoder):\n","        super(MyDataset, self).__init__()\n","        self.max_length = max_length\n","        self.tokenizer = tokenizer\n","        # self.texts = torch.tensor([self.tokenizer.encode(text,add_special_tokens=True) for text in texts])\n","        self.texts = texts\n","        self.labels = label_encoder.transform(labels)\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, index):\n","        text = self.texts[index]\n","        label = self.labels[index]\n","\n","        inputs = self.tokenizer(\n","            text,\n","            add_special_tokens=True,\n","            truncation=True,\n","            padding='max_length',\n","            max_length=self.max_length,\n","            return_tensors='pt'\n","        )\n","\n","        return {\n","            'input_ids': inputs['input_ids'].squeeze(),\n","            'attention_mask': inputs['attention_mask'].squeeze(),\n","            'labels': torch.tensor(label, dtype=torch.long)\n","        }"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:26:43.945608Z","iopub.status.busy":"2023-12-11T12:26:43.945216Z","iopub.status.idle":"2023-12-11T12:26:44.019229Z","shell.execute_reply":"2023-12-11T12:26:44.018472Z","shell.execute_reply.started":"2023-12-11T12:26:43.945581Z"},"id":"5RwziquRWUAP","trusted":true},"outputs":[],"source":["def find_max_seq_len(df):\n","    max_len = 0\n","    mat = df.to_numpy()[:,0].astype(str)\n","    for string in mat:\n","        tokens = string.split()\n","        max_len = max(max_len,len(tokens))\n","\n","    return max_len\n","\n","max_seq_len = find_max_seq_len(df_train)\n","# max_seq_len = 50 #Custom max length"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:26:44.545915Z","iopub.status.busy":"2023-12-11T12:26:44.545312Z","iopub.status.idle":"2023-12-11T12:26:44.590072Z","shell.execute_reply":"2023-12-11T12:26:44.589040Z","shell.execute_reply.started":"2023-12-11T12:26:44.545883Z"},"id":"IilMGRV4WUAP","trusted":true},"outputs":[],"source":["num_worker = 2\n","batch_size = 128\n","shuffle=True\n","\n","classes = ['normal', 'hatespeech', 'offensive']\n","label_encoder = LabelEncoder()\n","label_encoder.fit(classes)\n","\n","train_dataset = MyDataset(tokenizer, df_train.to_numpy()[:,0].astype(str), df_train.to_numpy()[:,1].astype(str),max_seq_len,label_encoder)\n","train_loader = DataLoader(train_dataset,batch_size=batch_size,num_workers=num_worker,shuffle=shuffle)\n","\n","valid_dataset = MyDataset(tokenizer, df_valid.to_numpy()[:,0].astype(str), df_valid.to_numpy()[:,1].astype(str),max_seq_len,label_encoder)\n","valid_loader = DataLoader(valid_dataset,batch_size=batch_size,num_workers=num_worker,shuffle=shuffle)\n","\n","test_dataset = MyDataset(tokenizer, df_test.to_numpy()[:,0].astype(str), df_test.to_numpy()[:,1].astype(str),max_seq_len,label_encoder)\n","test_loader = DataLoader(test_dataset,batch_size=batch_size,num_workers=num_worker,shuffle=shuffle)"]},{"cell_type":"markdown","metadata":{"id":"7Zji9ri9Aqr8"},"source":["4. Create a model class; here, you can use the classification model\n","from the huggingface library or the normal model without a\n","classification head and add your own classification layer above it.\n","Also, the dropouts and activation functions should be defined\n","here only."]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-12-11T12:26:50.677589Z","iopub.status.busy":"2023-12-11T12:26:50.676701Z","iopub.status.idle":"2023-12-11T12:26:50.815235Z","shell.execute_reply":"2023-12-11T12:26:50.814344Z","shell.execute_reply.started":"2023-12-11T12:26:50.677553Z"},"id":"JIAT056gWUAQ","outputId":"84dc8171-8ea9-42ea-eccd-7c9fe1e25f4c","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DataParallel(\n","  (module): BERT(\n","    (bert): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0-11): 12 x BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","    (additional_layers): Sequential(\n","      (0): Linear(in_features=768, out_features=512, bias=True)\n","      (1): ReLU()\n","      (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (3): Dropout(p=0.5, inplace=False)\n","      (4): Linear(in_features=512, out_features=256, bias=True)\n","      (5): ReLU()\n","      (6): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (7): Dropout(p=0.15, inplace=False)\n","      (8): Linear(in_features=256, out_features=128, bias=True)\n","      (9): ReLU()\n","      (10): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (11): Dropout(p=0.3, inplace=False)\n","      (12): Linear(in_features=128, out_features=3, bias=True)\n","    )\n","  )\n",")\n"]}],"source":["class BERT(nn.Module):\n","    def __init__(self,bert, num_classes,dropout):\n","        super(BERT, self).__init__()\n","        self.bert = bert\n","        # Define additional layers for custom classification head\n","        self.additional_layers = nn.Sequential(\n","            nn.Linear(768,512),\n","            nn.ReLU(),\n","            nn.BatchNorm1d(512),\n","            nn.Dropout(dropout),\n","            nn.Linear(512,256),\n","            nn.ReLU(),\n","            nn.BatchNorm1d(256),\n","            nn.Dropout(0.15),\n","            nn.Linear(256, 128),\n","            nn.ReLU(),\n","            nn.BatchNorm1d(128),\n","            nn.Dropout(0.3),\n","            nn.Linear(128,num_classes)\n","        )\n","\n","        # Weight initialization (XavierGlorot initialization)\n","        for layer in self.additional_layers:\n","            if isinstance(layer, nn.Linear):\n","                torch.nn.init.xavier_uniform_(layer.weight)\n","\n","    def forward(self,input_ids, attention_mask):\n","        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = self.additional_layers(outputs[1])\n","        return logits\n","\n","\n","num_classes = 3\n","hidden_dim = 512\n","dropout = 0.5\n","\n","model = BERT(bert,num_classes,dropout)\n","model= nn.DataParallel(model)\n","model.to(device)\n","print(model)"]},{"cell_type":"markdown","metadata":{"id":"fyyDEde3E5V2"},"source":["5. Design the train loop and the optimizers, schedulers, and loss\n","functions."]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:26:52.255456Z","iopub.status.busy":"2023-12-11T12:26:52.255057Z","iopub.status.idle":"2023-12-11T12:26:52.265780Z","shell.execute_reply":"2023-12-11T12:26:52.264837Z","shell.execute_reply.started":"2023-12-11T12:26:52.255422Z"},"id":"tYIIgahWWUAQ","trusted":true},"outputs":[],"source":["from sklearn.metrics import accuracy_score, f1_score\n","\n","def compute_accuracy(model, data_loader):\n","    model.eval()\n","    with torch.no_grad():\n","        all_targets = []\n","        all_predictions = []\n","\n","        for i, batch in enumerate(data_loader):\n","\n","            features = batch['input_ids'].long()\n","            attention_mask = batch['attention_mask'].long()\n","            targets = batch['labels'].long()\n","\n","            features = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            targets = batch['labels'].to(device)\n","\n","\n","            logits = model(features,attention_mask)\n","            _, predicted_labels = torch.max(logits, 1)\n","\n","            all_targets.extend(targets.cpu().numpy())\n","            all_predictions.extend(predicted_labels.cpu().numpy())\n","\n","    accuracy = accuracy_score(all_targets, all_predictions)\n","    f1 = f1_score(all_targets, all_predictions, average='macro')\n","    return (accuracy * 100, f1)"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:26:53.088114Z","iopub.status.busy":"2023-12-11T12:26:53.087343Z","iopub.status.idle":"2023-12-11T12:26:53.097235Z","shell.execute_reply":"2023-12-11T12:26:53.096220Z","shell.execute_reply.started":"2023-12-11T12:26:53.088085Z"},"id":"efS8qgBsiec6","trusted":true},"outputs":[],"source":["class_wts = compute_class_weight('balanced', classes = [0,1,2],y=train_loader.dataset.labels)\n","\n","class_wts = torch.tensor(class_wts, dtype=torch.float)\n","class_wts = class_wts.to(device)"]},{"cell_type":"markdown","metadata":{"id":"h5nKSgvrfoa2"},"source":["6. Train the model on the training data given.\n","7. Find validation set performance at the end of each epoch.\n","8. If validation set performance doesnâ€™t improve over k iterations\n","(called patience), stop training(early stopping)."]},{"cell_type":"code","execution_count":60,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-12-11T12:26:59.119401Z","iopub.status.busy":"2023-12-11T12:26:59.118748Z","iopub.status.idle":"2023-12-11T13:56:07.532218Z","shell.execute_reply":"2023-12-11T13:56:07.531105Z","shell.execute_reply.started":"2023-12-11T12:26:59.119367Z"},"id":"jkZIcNfwWUAR","outputId":"3df8d48a-125e-45e7-e12f-fe285bba29d2","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 1/20 | Patience: 0/5 \n","Training accuracy: 42.20%\n","Valid accuracy: 41.52%\n","Epoch: 2/20 | Patience: 0/5 \n","Training accuracy: 45.51%\n","Valid accuracy: 44.12%\n","Epoch: 3/20 | Patience: 0/5 \n","Training accuracy: 47.29%\n","Valid accuracy: 46.46%\n","Epoch: 4/20 | Patience: 0/5 \n","Training accuracy: 48.23%\n","Valid accuracy: 47.71%\n","Epoch: 5/20 | Patience: 0/5 \n","Training accuracy: 49.24%\n","Valid accuracy: 49.53%\n","Epoch: 6/20 | Patience: 1/5 \n","Training accuracy: 47.97%\n","Valid accuracy: 46.57%\n","Epoch: 7/20 | Patience: 0/5 \n","Training accuracy: 55.81%\n","Valid accuracy: 55.36%\n","Epoch: 8/20 | Patience: 0/5 \n","Training accuracy: 60.58%\n","Valid accuracy: 57.96%\n","Epoch: 9/20 | Patience: 0/5 \n","Training accuracy: 63.52%\n","Valid accuracy: 61.13%\n","Epoch: 10/20 | Patience: 0/5 \n","Training accuracy: 65.50%\n","Valid accuracy: 61.55%\n","Epoch: 11/20 | Patience: 0/5 \n","Training accuracy: 66.61%\n","Valid accuracy: 63.48%\n","Epoch: 12/20 | Patience: 0/5 \n","Training accuracy: 67.80%\n","Valid accuracy: 63.89%\n","Epoch: 13/20 | Patience: 0/5 \n","Training accuracy: 69.15%\n","Valid accuracy: 64.93%\n","Epoch: 14/20 | Patience: 0/5 \n","Training accuracy: 70.44%\n","Valid accuracy: 66.70%\n","Epoch: 15/20 | Patience: 1/5 \n","Training accuracy: 70.64%\n","Valid accuracy: 66.08%\n","Epoch: 16/20 | Patience: 2/5 \n","Training accuracy: 70.99%\n","Valid accuracy: 65.40%\n","Epoch: 17/20 | Patience: 3/5 \n","Training accuracy: 72.28%\n","Valid accuracy: 66.65%\n","Epoch: 18/20 | Patience: 0/5 \n","Training accuracy: 73.11%\n","Valid accuracy: 67.69%\n","Epoch: 19/20 | Patience: 1/5 \n","Training accuracy: 73.69%\n","Valid accuracy: 67.22%\n","Epoch: 20/20 | Patience: 2/5 \n","Training accuracy: 74.74%\n","Valid accuracy: 67.43%\n"]}],"source":["from torch.optim.lr_scheduler import OneCycleLR\n","\n","num_epochs = 20\n","optimizer = optim.AdamW(model.parameters(), lr=0.0005)\n","\n","lr_scheduler = OneCycleLR(\n","        optimizer = optimizer,\n","        max_lr = 0.005,\n","        epochs = num_epochs,\n","        steps_per_epoch = len(train_loader)\n","    )\n","\n","criterion = nn.CrossEntropyLoss(weight=class_wts)\n","\n","for param in model.module.bert.parameters():\n","    param.requires_grad = False\n","\n","best_model_state_dict = model.state_dict()\n","val_acc = 0\n","val_acc_max = 0\n","patience = 5\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    batch_idx = 0\n","\n","    if epoch== num_epochs // 3:\n","        for param in model.module.bert.parameters():\n","            param.requires_grad = True\n","\n","        optimizer = optim.AdamW(model.parameters(), lr=0.00001)\n","        lr_scheduler = OneCycleLR(\n","                optimizer = optimizer,\n","                max_lr = 0.0001,\n","                epochs = num_epochs,\n","                steps_per_epoch = len(train_loader)\n","            )\n","\n","    for batch in train_loader:\n","        batch_idx+=1\n","\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        outputs = model(input_ids,attention_mask)\n","\n","        loss = criterion(outputs,labels)\n","        optimizer.zero_grad()\n","\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","\n","    val_acc =  compute_accuracy(model, valid_loader)[0]\n","    val_acc_max = max(val_acc, val_acc_max)\n","\n","    if val_acc_max > val_acc:\n","        k +=1\n","    else:\n","        best_model_state_dict = model.state_dict()\n","        torch.save(best_model_state_dict,'classifier_weights.pth')\n","        k = 0\n","\n","    with torch.set_grad_enabled(False):\n","        print(f'Epoch: {epoch+1}/{num_epochs} | Patience: {k}/{patience}',\n","              f'\\nTraining accuracy: '\n","              f'{compute_accuracy(model, train_loader)[0]:.2f}%'\n","              f'\\nValid accuracy: '\n","              f'{val_acc:.2f}%')\n","\n","    if k >= patience:\n","        break\n"]},{"cell_type":"markdown","metadata":{"id":"-ihbxBp-foa3"},"source":["9. Load best model weights based on the validation set\n","performance.\n","10. Find performance on the test set."]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2023-12-11T14:00:49.481233Z","iopub.status.busy":"2023-12-11T14:00:49.480760Z","iopub.status.idle":"2023-12-11T14:01:12.157522Z","shell.execute_reply":"2023-12-11T14:01:12.156231Z","shell.execute_reply.started":"2023-12-11T14:00:49.481190Z"},"id":"Or47K3A3Xt0J","outputId":"0aae9817-9357-4f9a-c294-d503d5624c5c","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The Accuracy of the model on the Test set is: 67.87941787941789% \n","The macro-f1 score of the model on test set is: 0.6685580368108469\n"]}],"source":["model.load_state_dict(torch.load(r'classifier_weights.pth'))\n","model.eval()\n","\n","print(f'The Accuracy of the model on the Test set is: {compute_accuracy(model, test_loader)[0]}%',\n","      f'\\nThe macro-f1 score of the model on test set is: {compute_accuracy(model, test_loader)[1]}')"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2023-12-11T14:01:20.813753Z","iopub.status.busy":"2023-12-11T14:01:20.812996Z","iopub.status.idle":"2023-12-11T14:01:21.452022Z","shell.execute_reply":"2023-12-11T14:01:21.450518Z","shell.execute_reply.started":"2023-12-11T14:01:20.813715Z"},"trusted":true},"outputs":[],"source":["torch.save(model,'classifier.pth')"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2023-12-11T14:09:41.276619Z","iopub.status.busy":"2023-12-11T14:09:41.276205Z","iopub.status.idle":"2023-12-11T14:09:41.670631Z","shell.execute_reply":"2023-12-11T14:09:41.669669Z","shell.execute_reply.started":"2023-12-11T14:09:41.276587Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.45174727 0.7216576  0.46821246]]\n"]}],"source":["model = torch.load('classifier.pth')\n","\n","test_sent = \"<user> i am bit confused coz chinese ppl can not access twitter thn how this ching chong using it i think he pakistani ðŸ¤” ðŸ¤” ðŸ¤”\"\n","\n","inputs = tokenizer(test_sent, return_tensors = 'pt')\n","with torch.no_grad():\n","    model.eval()\n","    logits = model(inputs['input_ids'],inputs['attention_mask'])\n","\n","print((logits.cpu().numpy()))"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2023-12-11T14:09:41.672671Z","iopub.status.busy":"2023-12-11T14:09:41.672382Z","iopub.status.idle":"2023-12-11T14:09:41.678549Z","shell.execute_reply":"2023-12-11T14:09:41.677502Z","shell.execute_reply.started":"2023-12-11T14:09:41.672647Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["hatespeech\n"]}],"source":["out_class = np.argmax(logits.cpu().numpy())\n","classes_dict = {0 : 'normal', 1: 'hatespeech', 2 : 'offensive'}\n","print(classes_dict[out_class])"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30616,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
